# identifies lascar files in the dropbox
# load the files once to get SN, date, lascarID, and firstline info to use in duplicate checking
# match this info to the calibration factors
# then load files in groups by SN and process and save the data in batches by SN. Apply calibration factors when available. Plot the data in the same batches. (THIS STEP TAKES A LONG TIME)
# Generate overall parameters for the processed files
# Generate forms to use in validation.
# merges validation info back into the parameters files and saves them.

# The overall parameters file generated by this process is: "CO_parameters_all_(X)sessions_(DATE).rds")

# The most recent parameters file is: 
params <- readRDS("~/Dropbox/Ghana_exposure_data_SHARED (1)/CO_files_processed/FINAL_CO_parameters_withvalidation_2016Jun14.rds")

# Codebook:
# ~/Dropbox/Ghana_exposure_data_SHARED (1)/CO_files_processed/GRAPHS _CO_parameters_codebook_2016Jun07.csv


# Validation info:
# validation_info <- readRDS("~/Dropbox/Ghana_exposure_data_SHARED (1)/CO_files_processed/CO_validation_info_11892sessions_2016Jun05.rds")


# Load packages
require(lubridate)
require(plyr)
require(dplyr)
require(ggplot2)
require(scales)
require(reshape2)

#########
# note some dropboxes referred to as ~/Dropbox/Ghana_exposure_data_SHARED_2014 and some as ~/Dropbox/Ghana_exposure_data_SHARED_2014, do find/replace
##########

####
# files needed: Calibration Factors, generated from the script "lascar_calibration_Jan2016.R"

cf_new <- readRDS("/Users/Adoption/Dropbox/Ghana_exposure_data_SHARED_2014/CO_calibration_documents/Calibration Factors/Datasets/calib_factors_bymonth_interp_2016Apr29.rds")


#####################
# To load data from original Lascar .csv files
#####################


#create vector of all file names  -----
files<-list.files("~/Dropbox/Ghana_exposure_data_SHARED_2014/Main_study_exposure_assessment",recursive=T,pattern="^(CU_CO|CU_C0|CO_USB|COL_USB|CU-CO|CU-C0|CO-USB|COL-USB)", full.names=T) 
length(files) #6656 / 6937 / Jan 29 7472 / Jan 17, 2016 11681 /Feb 1 11818/ June 6 12197/ June 10 11898


# If you want to only include previously unvalidated files, do this
# unvalidated <- readRDS("/Users/Adoption/Dropbox/Ghana_exposure_data_SHARED_2014/CO_files_processed/CO_parameters_unvalidated_4734sessions_Jan30.rds")

# nrow(unvalidated) # 4734

# files <- files[basename(files) %in% basename(unvalidated$file_all)]
# length(files) # 4735
sum(duplicated(basename(files))) #0
files <- files[!duplicated(basename(files))]
length(files) # 12185

# make a data frame of info from the files--------------
Lascar_data <- data.frame(file = files, stringsAsFactors = FALSE)
Lascar_data$file2 <- basename(files)

# grab the Lascar ID
lascar_pattern <- "(CU_CO.{4}|CU_C0.{4}|CO_USB.{4}|COL_USB.{4}|CU-CO.{4}|CU-C0.{4}|CO-USB.{4}|COL-USB.{4}|CU-CO.{4}|CU-C0.{4}|CO-USB.{4}|COL-USB.{4})" #note requires that lascar values be entered as three digits

Lascar_data$lascar<-regmatches(Lascar_data$file2, regexpr(lascar_pattern, Lascar_data$file2))

# make Lascar IDs consistent
length(unique(Lascar_data$lascar))
Lascar_data$lascar <- gsub("C0", "CO", Lascar_data$lascar)
Lascar_data$lascar <- gsub("-", "_", Lascar_data$lascar)

# get rid of hanging "_" at end of Lascar_data$lascar
Lascar_data$lascar <- ifelse(substr(Lascar_data$lascar, start = nchar(Lascar_data$lascar), stop = nchar(Lascar_data$lascar)) == "_", 
                              substr(Lascar_data$lascar, 1, nchar(Lascar_data$lascar)-1),
                              Lascar_data$lascar)


# load data to get SNs ----

get.info <- function(x) { ####### read in first row of each data file and extract pertinent info
  
  dt <- read.csv(x, stringsAsFactors=F, header=T, nrows = 1)[,1:5]

  dt$file2 <- basename(x)
  dt$lascar_infile <- names(dt)[1]
  dt$lascar_infile <- gsub("C0", "CO", dt$lascar)
  dt$lascar_infile <- gsub("-", "_", dt$lascar)
  dt$lascar_infile <- gsub("\\.", "_", dt$lascar)
  dt$SN<- dt$Serial.Number
  dt$firstdate <- dmy_hms(dt$Time, tz="GMT")
  dt$monthyear <- paste(months(dt$firstdate), year(dt$firstdate), sep = "_")
  dt$firstline <- paste(dt[,2:5], collapse = "/")
  dt <- dt[, c("file2", "SN", "lascar_infile", "monthyear", "firstline", "firstdate")]
  dt
  }


file_data <- ldply(Lascar_data$file, get.info, .progress = "text")

Lascar_data <- merge(Lascar_data, file_data, by = "file2")

# identifying duplicate files
samefiles <- Lascar_data$firstline[duplicated(Lascar_data$firstline)]
same <- filter(Lascar_data, firstline %in% samefiles) %>% arrange(firstline)
same <- same[, c("file2", "file", "firstline")]
same$file <- gsub("/Users/Adoption", "~", same$file)
write.csv(same, file = "duplicated_files.csv")

#Lascar_data <- Lascar_data[!duplicated(Lascar_data$firstline),] # remove duplicates
nrow(Lascar_data) #6623/ Jan 29 7152/ Jan 15, 2016 5041/ Feb 1 4726 / May 9 832/ June 6 11854/ June 10 11898

id_pattern <- "BM....."
Lascar_data$mstudyid <- regmatches(Lascar_data$file2, regexpr(id_pattern, Lascar_data$file2))
Lascar_data$newid <- paste(Lascar_data$lascar, Lascar_data$SN, Lascar_data$mstudyid, year(Lascar_data$firstdate), month(Lascar_data$firstdate), day(Lascar_data$firstdate), sep = "_")

table(year(Lascar_data$firstdate))

# save the SN data ----- "Lascar_SN_data_..."
saveRDS(Lascar_data, file = paste0("Lascar_SN_data_", format(Sys.Date(), format = "%Y%b%d"), ".rds"))

# match the CF (pulls the CF from the month of the last day of monitoring) - see "lascar_calibration_Jan2016.R"
cf_new <- readRDS("~/Dropbox/Ghana_exposure_data_SHARED_2014/CO_calibration_documents/Calibration Factors/Datasets/calib_factors_bymonth_interp_2016Apr29.rds")


Lascar_data$cf <- NA
Lascar_data$cf_conf <- NA

# match the CF according to the serial number, month and year.
for (i in 1:nrow(Lascar_data)){
  cfmatch <- match(Lascar_data$SN[i], cf_new$SN) 
  Lascar_data$cf[i] <- cf_new[cfmatch, names(cf_new) == Lascar_data$monthyear[i]]
  Lascar_data$cf_conf[i] <- cf_new[cfmatch, names(cf_new) == paste0(Lascar_data$monthyear[i], "_conf")]
}
Lascar_data$cf <- as.numeric(Lascar_data$cf)

# # get rid of files called "dropbox.attributes"
# dropbox_pattern <- "dropbox.attributes"
# Lascar_data <- Lascar_data[regexpr(dropbox_pattern, Lascar_data$file) == -1,]

summary(Lascar_data) # 345 NAs for cf
length(unique(Lascar_data$SN[is.na(Lascar_data$cf)])) # 25 unique Lascars have no calib info

# save Lascar_data with CFs added: "Lascar_data_cf_...."
saveRDS(Lascar_data, file = paste0("Lascar_data_cf_", format(Sys.Date(), format = "%Y%b%d"), ".rds" ))


#### DONE GETTING INITIAL INFO #####


# Lascar.import function -------
lascar.import <- function(file,cf, cf_conf) { 
  dt <- read.csv(file, stringsAsFactors=F, header=T)[,1:5]
  dt$lascar <- names(dt)[1]
  dt$lascar <- gsub("C0", "CO", dt$lascar)
  dt$lascar <- gsub("-", "_", dt$lascar)
  dt$SN<- dt$Serial.Number[1]
  dt$datetime <- dmy_hms(dt$Time, tz="GMT")
  dt$rd.datetime <- as.character(round(dt$datetime, 'min')) # rounding by minute
  dt<-dt %>% group_by(rd.datetime) %>% dplyr::summarise(mean(CO.ppm.), lascar[1], SN[1]) # summarize by minute
  names(dt) <- c('datetime','co', 'lascar', 'SN')
  dt$datetime <- ymd_hms(dt$datetime)
  dt$cf <- cf
  dt$cf_conf <- ifelse(!is.na(dt$cf[1]), cf_conf, "lo") # if CF is NA, set as low
  cfgood <- !is.na(dt$cf[1]) & dt$cf[1]>=0.6 & dt$cf[1]<=1.2 
  if(cfgood == TRUE) dt$co_corr <- dt$co/dt$cf
  if(cfgood == FALSE) dt$co_corr <- dt$co/0.85 # if CF is NA < 0.6, or > 1.2,  adjust with the mean
  dt
}


#################### START LOOP HERE if working from raw Lascar files ###################
# If working from raw files be sure to comment out section at "START HERE IF WORKING FROM SAVED .RDS DATA
## NOTE: THE FOLLOWING STEPS FROM THE RAW DATA TAKE A LONG TIME!

# Lascar_data <- readRDS("~/Dropbox/Ghana_exposure_data_SHARED_2014/CO_calibration_documents/Calibration Factors/Datasets/Lascar_data_cf_2016Feb01.rds")

##################################
# set a directory for the saved data. Also scroll down for the plot directory.
directory <- "/Users/Adoption/Dropbox/Ghana_exposure_data_SHARED_2014/CO_files_processed/FINAL_2016June10/CO_stacked files/"
##################################


ptm <- proc.time()

for (i in 110:length(unique(Lascar_data$SN))) { # length(unique(Lascar_data$SN))
  files_bySN <- Lascar_data[Lascar_data$SN == unique(Lascar_data$SN)[i], c("file", "cf", "cf_conf")]
  
  CO_stacked <- mdply(files_bySN, lascar.import, .progress = "text") # mdply so can supply multiple arguments to lascar.import. Variable names of files_bySN must match those in lascar.import (file, cf, cf_conf)
  
  CO_stacked <- CO_stacked[!is.na(CO_stacked$co),] # removing NAs
  
  
  # grab mother and child id info
  id_pattern <- "BM....."
  CO_stacked$mstudyid <- regmatches(CO_stacked$file, regexpr(id_pattern, CO_stacked$file))
  
  child_pattern <- "BM....C"
  CO_stacked$cstudyid <- regexpr(child_pattern, CO_stacked$file)
  CO_stacked$cstudyid <- ifelse(CO_stacked$cstudyid == -1, NA, substr(x = CO_stacked$file, start = CO_stacked$cstudyid, stop = CO_stacked$cstudyid + 6))
  
  # grab session info - NEED TO DO WITH BASENAME(FILE) not FILE
  # grab session info: do in multiple steps to deal with bad value propagation after NA
  session_pattern <- "(s_[0123456789]{1,2}|s[0123456789]{1,2})"
  CO_stacked$session <- regmatches(basename(CO_stacked$file), regexpr(session_pattern, basename(CO_stacked$file), ignore.case =TRUE))
  CO_stacked$session <- tolower(CO_stacked$session)
  
  # order from most recent to oldest
  CO_stacked <- CO_stacked[order(CO_stacked$datetime),]
  
  # simplify Lascar names
  CO_stacked$lascar <- gsub("\\.", "_", CO_stacked$lascar)
  
 
    # separate and save the data by SN
    saveRDS(CO_stacked, file = paste0(directory, "CO_stacked_", CO_stacked$lascar[1], "_", CO_stacked$SN[1],".rds"))
    
    
    
    ########################## START HERE IF WORKING FROM SAVED .RDS DATA ######################
    #     #  If working from saved .rds data START HERE and run this section thru first print[i], otherwise comment it out along with the print[i] before the loop closure------
    #     
    #     
    # savedfiles <- list.files("/Users/ashlinn/Dropbox/Ghana_exposure_data_SHARED (1)/CO_files_processed/29Jan2015/CO_stacked files/", full.names = TRUE)
    #     length(savedfiles)
    #     for (i in 1:length(savedfiles)) {
          #CO_stacked <- readRDS(savedfiles[i])
      #   CO_stacked <- arrange(CO_stacked, datetime) # ascending by date
    
    #########################
    
    
    #########################
    # set a directory for the saved plots & a meanCF to use for plots that have no CF
    #########################
    plotdirectory <- "/Users/Adoption/Dropbox/Ghana_exposure_data_SHARED_2014/CO_files_processed/FINAL_2016June10/Plots by SN/"
    meancf <- 0.85 #(mean across all units' CFs that were between 0.6 and 1.2 between Feb and Dec 2014)
    
    
    identifier <- paste("allplots", gsub("\\.", "_", CO_stacked$lascar[1]), CO_stacked$SN[1], sep = "_")
    
    # plot
    pdf(file = paste0(plotdirectory, identifier,".pdf"), height = 10, width = 10)
    par(mfrow = c(3,3))
    for (j in 1:length(unique(CO_stacked$file))) {
      CO_bysession <- filter(CO_stacked, file == unique(file)[j])
      
      # evaluate parameters
      cfgood <- !is.na(CO_bysession$cf[1]) & CO_bysession$cf[1] >=0.6 & CO_bysession$cf[1] <=1.2 
      mean <- ifelse(cfgood ==TRUE, round(mean(CO_bysession$co_corr, na.rm = TRUE), digits = 2), round(mean(CO_bysession$co/meancf, na.rm = TRUE), digits = 2))
      q90 <-ifelse(cfgood ==TRUE, round(quantile(CO_bysession$co_corr, probs = 0.9, na.rm = TRUE), digits = 2), round(quantile(CO_bysession$co/meancf, probs = 0.9, na.rm = TRUE), digits = 2))
      q98 <- ifelse(cfgood ==TRUE, round(quantile(CO_bysession$co_corr, probs = 0.98, na.rm = TRUE), digits =2), round(quantile(CO_bysession$co/meancf, probs = 0.98, na.rm = TRUE), digits =2))
      sd <- ifelse(cfgood ==TRUE, round(sd(CO_bysession$co_corr, na.rm =TRUE), digits = 2), round(sd(CO_bysession$co/meancf, na.rm =TRUE), digits = 2))
      min <- ifelse(cfgood ==TRUE, round(min(CO_bysession$co_corr, na.rm = TRUE), digits = 2), round(min(CO_bysession$co/meancf, na.rm = TRUE), digits = 2))
      invalid <- q98==0|q90 > 20|sd > 60|min > 10
      
      
      # plot
      title <- paste(j, CO_bysession$lascar[1], CO_bysession$SN[1], "\n", format(CO_bysession$datetime[1], format = "%b %d %Y"), "CF=", round(CO_bysession$cf[1], digits = 2), "CF_conf=", CO_bysession$cf_conf[1], "\n mean=", mean, " sd=", sd, " q90=", q90, " q98=", q98, "min=", min)
      range <- ifelse(cfgood ==TRUE, max(CO_bysession$co_corr), max(CO_bysession$co)/meancf)
      
      plot(CO_bysession$datetime, CO_bysession$co, type = "l", ylim = c(0, range), main = "" , xlab = paste(CO_bysession$mstudyid[1], CO_bysession$session[1]), ylab = "", lwd = 2, col = "black")
      
      if (cfgood ==TRUE & CO_bysession$cf_conf[1] == "hi") lines(CO_bysession$datetime, CO_bysession$co_corr, col = alpha("green",0.6), lwd = 2) # green if hi confidence
      
      # if (cfgood ==TRUE & CO_bysession$cf_conf[1] == "medium") lines(CO_bysession$datetime, CO_bysession$co_corr, col = alpha("plum",0.6), lwd = 2) # plum if medium confidence
      if (cfgood ==TRUE & CO_bysession$cf_conf[1] == "lo") lines(CO_bysession$datetime, CO_bysession$co_corr, col = alpha("coral",0.6), lwd = 2) # coral if low confidence
      if (cfgood ==FALSE | CO_bysession$cf_conf[1] == "none")  lines(CO_bysession$datetime, CO_bysession$co/meancf, col = alpha("darkgrey", 0.6), lwd = 2) # plot the mean-corrected values in grey if conf none or if there is no CF for this instrument
      
      mtext("CO (ppm)", side = 2, line = 2, cex = 0.7)
      legend(x="topright", legend = c(paste("CO, mean = ", round(mean(CO_bysession$co), digits=2)), paste("CO_corr, mean =", ifelse(cfgood ==TRUE, round(mean(CO_bysession$co_corr), digits = 2), round(mean(CO_bysession$co/meancf), digits =2 )))), col = c("black", ifelse((cfgood ==TRUE & CO_bysession$cf_conf[1] == "hi"), "green", ifelse((cfgood == TRUE & CO_bysession$cf_conf == "lo"), "coral", "darkgrey"))), lwd = 2, cex = 0.9)
      
      if (invalid == TRUE &!is.na(invalid)) title(main = title,  cex.main = 0.95, col.main = "red") # change title to red if any of the validity criteria are invalid
      if (invalid == FALSE | is.na(invalid)) title(main = title,  cex.main = 0.95)
      if (difftime(CO_bysession$datetime[nrow(CO_bysession)],CO_bysession$datetime[1],units = "hours") < 44) title(main = title,  cex.main = 0.95, col.main = "blue") # change title to blue if < 44 hours
      
    }
    dev.off()
    
  
  
  
  #}
  # Loop ends here if just plotting and not saving data
  
  print(i)
  print(unique(CO_stacked$lascar))
  print(unique(CO_stacked$SN))
  print(length(unique(CO_stacked$file)))
}

proc.time()-ptm


########################################### END plot saving ############



####################################################################
### Calculating parameters for the saved data-------
####################################################################

COfiles <- list.files("/Users/Adoption/Dropbox/Ghana_exposure_data_SHARED_2014/CO_files_processed/FINAL_2016June10/CO_stacked files",recursive=FALSE, pattern = ".rds",full.names=TRUE) 
length(COfiles) #293


# new adding day1, day2, day3 24-hour averages, and 72-hour average if available
CO.parameters <- function(x) { 
  CO_stacked_bySN <- readRDS(x)
  data <- CO_stacked_bySN %>% 
    group_by(file) %>% 
    summarise(mstudyid = mstudyid[1], 
              cstudyid = cstudyid[1], 
              session = session[1], 
              lascar = lascar[1], 
              sn = SN[1],  
              firstdate = datetime[1], 
              lastdate = datetime[n()], 
              co_mean = mean(co, na.rm = TRUE), 
              co_sd = sd(co, na.rm = TRUE), 
              co_q75 = quantile(co, probs = 0.75, na.rm = TRUE), 
              co_q80 = quantile(co, probs = 0.8, na.rm = TRUE), 
              co_q85 = quantile(co, probs = 0.85, na.rm = TRUE), 
              co_q90 = quantile(co, probs = 0.9, na.rm = TRUE), 
              co_q95 = quantile(co, probs = 0.95, na.rm = TRUE), 
              co_q98 = quantile(co, probs = 0.98, na.rm = TRUE), 
              co_cf = cf[1], 
              co_cf_conf = cf_conf[1], 
              co_mean_corr = mean(co_corr, na.rm = TRUE), 
              co_sd_corr = sd(co_corr, na.rm = TRUE), 
              co_q75_corr = quantile(co_corr, probs = 0.75, na.rm = TRUE), 
              co_q80_corr = quantile(co_corr, probs = 0.8, na.rm = TRUE), 
              co_q85_corr = quantile(co_corr, probs = 0.85, na.rm = TRUE), 
              co_q90_corr = quantile(co_corr, probs = 0.9, na.rm = TRUE), 
              co_q95_corr = quantile(co_corr, probs = 0.95, na.rm = TRUE), 
              co_q98_corr = quantile(co_corr, probs = 0.98, na.rm = TRUE), 
              
              # raw
              co_day1_mean = ifelse(difftime(datetime[n()], datetime[1], units = "hours") >= 24, mean(co[datetime < datetime[1] + hours(24)], na.rm = TRUE), NA), 
              co_day2_mean = ifelse(difftime(datetime[n()], datetime[1], units = "hours") >= 48, mean(co[datetime >= datetime[1] + hours(24) & datetime < datetime[1] + hours(48)], na.rm = TRUE), NA), 
              co_day3_mean = ifelse(difftime(datetime[n()], datetime[1], units = "hours") >= 72, mean(co[datetime >= datetime[1] + hours(48) & datetime < datetime[1] + hours(72)], na.rm = TRUE), NA), 
              co_mean_first48 = ifelse(difftime(datetime[n()], datetime[1], units = "hours") >= 48, mean(co[datetime < datetime[1] + hours(48)], na.rm = TRUE), NA),  
              co_mean_first72 = ifelse(difftime(datetime[n()], datetime[1], units = "hours") >= 72, mean(co[datetime < datetime[1] + hours(72)], na.rm = TRUE), NA),
              # corrected
              co_day1_mean_corr = ifelse(difftime(datetime[n()], datetime[1], units = "hours") >= 24, mean(co_corr[datetime < datetime[1] + hours(24)], na.rm = TRUE), NA), 
              co_day2_mean_corr = ifelse(difftime(datetime[n()], datetime[1], units = "hours") >= 48, mean(co_corr[datetime >= datetime[1] + hours(24) & datetime < datetime[1] + hours(48)], na.rm = TRUE), NA), 
              co_day3_mean_corr = ifelse(difftime(datetime[n()], datetime[1], units = "hours") >= 72, mean(co_corr[datetime >= datetime[1] + hours(48) & datetime < datetime[1] + hours(72)], na.rm = TRUE), NA), 
              co_mean_first48_corr = ifelse(difftime(datetime[n()], datetime[1], units = "hours") >= 48, mean(co_corr[datetime < datetime[1] + hours(48)], na.rm = TRUE), NA),  
              co_mean_first72_corr = ifelse(difftime(datetime[n()], datetime[1], units = "hours") >= 72, mean(co_corr[datetime < datetime[1] + hours(72)], na.rm = TRUE), NA),
              co_hours = as.numeric(round(difftime(datetime[n()], datetime[1], units = "hours"), digits = 1)))
  data
}

CO_parameters <- ldply(COfiles, CO.parameters, .progress = "text")

CO_parameters$lascar <- gsub("\\.", "_", CO_parameters$lascar)
CO_parameters$file_all <- CO_parameters$file
CO_parameters$file <- basename(CO_parameters$file_all)



CO_parameters <- CO_parameters[!is.na(CO_parameters$co_mean),] # removing NAs
nrow(CO_parameters) #7152 / 2016 Jan17: 5041 / May 9: 539/ June 6 11854/ June 10 11898


# Save the parameters - without validation info.
saveRDS(CO_parameters, file = paste0("CO_parameters_", nrow(CO_parameters), "sessions_", format(Sys.Date(), format = "%Y%b%d"), ".rds"))




# ######## Make forms to fill in later for validation ---------------
# savedfiles <- list.files("~/Dropbox/Ghana_exposure_data_SHARED_2014/CO_files_processed/2016May09/CO_stacked files", full.names = TRUE)
# length(savedfiles)
# 
# directory <- "~/Dropbox/Ghana_exposure_data_SHARED_2014/CO_files_processed/2016May09/Validation Forms 2016May09/"
# 
# meancf <- 0.85
# for (i in 1:length(savedfiles)){ #
#   form <- data.frame()
#   CO_stacked_bySN <- readRDS(savedfiles[i])
#   CO_stacked_bySN <- arrange(CO_stacked_bySN, datetime)
#   
#   for (j in 1:length(unique(CO_stacked_bySN$file))) {
#     CO_bysession <- filter(CO_stacked_bySN, file == unique(file)[j])
#     CO_bysession <- arrange(CO_bysession, datetime)
#     info <- CO_bysession[1, c(1,2,4:6,8:10)]
#     info$file <- basename(info$file)
#     info$number <- j
#     info <- info[, c(9, 1,3,4,6:8,2,5)]
#     info$duration_valid <- ifelse(difftime(CO_bysession$datetime[nrow(CO_bysession)], CO_bysession$datetime[1], units = "hours") >= 44, 1, 3)
#     info$cf_valid <- ifelse((info$cf > 0.6 & info$cf < 1.2 &!is.na(info$cf)), 1, ifelse(((info$cf > 0.2 & info$cf < 0.6 &!is.na(info$cf))|(info$cf > 1.2 &!is.na(info$cf))), 2, 3))
#     info$lascar <- gsub("\\.", "_", info$lascar)
#     
#     # evaluate co validity parameters
#     q90 <-ifelse(!is.na(CO_bysession$cf[1]), round(quantile(CO_bysession$co_corr, probs = 0.9, na.rm = TRUE), digits = 2), round(quantile(CO_bysession$co/meancf, probs = 0.9, na.rm = TRUE), digits = 2))
#     q98 <- ifelse(!is.na(CO_bysession$cf[1]), round(quantile(CO_bysession$co_corr, probs = 0.98, na.rm = TRUE), digits =2), round(quantile(CO_bysession$co/meancf, probs = 0.98, na.rm = TRUE), digits =2))
#     sd <- ifelse(!is.na(CO_bysession$cf[1]), round(sd(CO_bysession$co_corr, na.rm =TRUE), digits = 2), round(sd(CO_bysession$co/meancf, na.rm =TRUE), digits = 2))
#     min <- ifelse(!is.na(CO_bysession$cf[1]), round(min(CO_bysession$co_corr, na.rm = TRUE), digits = 2), round(min(CO_bysession$co/meancf, na.rm = TRUE), digits = 2))
#     invalid <- q98==0|q90 > 20|sd > 60|min > 10
#     info$co_valid_init <- ifelse(invalid == FALSE, 1, 2)
#     info$NEW_CF <- ""
#     info$CO_VALID <- ""
#     info$NOTES_NOTES_NOTES <- ""
#     info$Validated.by <- ""
#     form <- rbind(form, info)
#     write.csv(form, file = paste0(directory, "ValidityForm_", form$lascar[1], "_",form$SN[1], "_",format(Sys.Date(), format = "%Y%b"), ".csv"), row.names = FALSE)
#   }
#   
#   print(i)
# }

# ########## STOP AND DO VISUAL VALIDATION ##############
# 
# ## Add validation data in to CO_parameters --------
# ## The forms reviewed in the Jan 2015 folder do not have correct CFs so just merge the visual CO validity data:  co_valid, NOTES_NOTES_NOTES, and Validated.by columns
# 
# # load and merge CO validition forms 
# validforms <- list.files("~/Dropbox/Ghana_exposure_data_SHARED (1)/CO_files_processed/2016May09/Validation Forms Completed 2016May09/", full.names = TRUE)
# length(validforms) # 124
# 
# import.list <- llply(validforms, read.csv, stringsAsFactors = FALSE) # warnings about "incomplete final lines" are ok?
# CO_validation <- Reduce(function(x, y) merge(x, y, all=T), import.list, accumulate=F)
# 
# # check row length
# rows <- 0
# for (i in 1:length(import.list)) { 
#   a <- nrow(import.list[[i]])
#   rows <- sum(rows, a)
#   rows
# }
# rows # 539
# 
# unique(CO_validation$CO_VALID) # check that only contains 1,2,3, and NA. If not, go back to forms and fix!
# 
# # # merge by "file" in validation files (need to create similar variable in CO_parameters)
# # CO_parameters$file_all <- CO_parameters$file
# # CO_parameters$file <- basename(CO_parameters$file)
# CO_parameters <- readRDS("/Users/ashlinn/Dropbox/Ghana_exposure_data_SHARED (1)/CO_files_processed/CO_parameters_539sessions_2016May09.rds")
# 
# # make a unique id to match both data frames
# CO_parameters$year <- year(CO_parameters$firstdate)
# CO_parameters$month <- month(CO_parameters$firstdate)
# CO_parameters$day <- day(CO_parameters$firstdate)
# CO_parameters$newid <- paste(CO_parameters$lascar, CO_parameters$sn, CO_parameters$mstudyid, CO_parameters$year, CO_parameters$month, CO_parameters$day, sep = "_")
# 
# 
# CO_validation$year <- year(mdy_hm(CO_validation$datetime, tz = "GMT"))
# CO_validation$year <- ifelse(as.numeric(CO_validation$year < 2000), CO_validation$year + 2000, CO_validation$year)
# CO_validation$month <- month(mdy_hm(CO_validation$datetime, tz = "GMT"))
# CO_validation$day <- day(mdy_hm(CO_validation$datetime, tz = "GMT"))
# CO_validation$newid <- paste(CO_validation$lascar, CO_validation$SN, CO_validation$mstudyid, CO_validation$year, CO_validation$month, CO_validation$day, sep = "_")
# 
# # check what's going on with duplicates
# sum(duplicated(CO_validation$newid)) #0
# sum(duplicated(CO_parameters$newid)) #14
# dups <- CO_parameters$newid[duplicated(CO_parameters$newid)]
# CO_parameters[CO_parameters$newid %in% dups,c("file", "co_mean", "newid")] %>% arrange(newid)
# 
# # these are all real duplicates so remove
# CO_parameters <- CO_parameters[!duplicated(CO_parameters$newid),]
# 
# nrow(CO_parameters[CO_parameters$newid %in% CO_validation$newid,]) #5041
# 
# # subset into validated before and validated now
# former <- CO_parameters[!CO_parameters$newid %in% CO_validation$newid,]
# summary(former$visually_valid) # only 1-3
# 
# new <- CO_parameters[CO_parameters$newid %in% CO_validation$newid,]
# 
# # get rid of "visually_valid", "visual_notes", "validated.by" if they exist
# new <- subset(new, select = -c(visually_valid, visual_notes, validated.by))
# 
# CO_all <- merge(new, CO_validation[,c("newid", "CO_VALID", "NOTES_NOTES_NOTES", "Validated.by")], all.x = TRUE, by = "newid")
# 
# colnames(CO_all) <- tolower(colnames(CO_all))
# colnames(CO_all)[colnames(CO_all) == "co_valid"] <- "visually_valid"
# colnames(CO_all)[colnames(CO_all) == "notes_notes_notes"] <- "visual_notes"
# 
# # function to convert blanks to NA 
# 
# blank2na <- function(x){ 
#   z <- gsub("\\s+", "", x)  #make sure it's "" and not " " etc
#   x[z==""] <- NA 
#   return(x)
# }
# 
# CO_all$visual_notes <- blank2na(CO_all$visual_notes)
# CO_all$validated.by <- blank2na(CO_all$validated.by)
# 
# table(CO_all$visually_valid, useNA = "always")
# 
# ### Calculate duration validity: 1 if >=44 hours, 2 if between 18 and 44 hours, 3 if < 18 hours -------
# CO_all$duration_valid <- ifelse(CO_all$co_hours >=44, 1, ifelse(CO_all$co_hours >=18, 2, 3))
# 
# ### Calculate overall validity
#  ## 1 If cf_conf hi, visual validity =1 , duration =1
#  ## 2 if cf_conf hi, visual validity =2, duration = 1 or 2
#  ## 2 if cf_conf = hi, visual validity = 1, duration = 2
#  ## 3 if cf_conf lo, visual validity =1 or 2, duration =1 or 2
#  ## 4 if visual validity= 3 or duration = 3 or cf_conf = none
# 
# CO_all$overall_valid <- ifelse(CO_all$co_cf_conf == "hi" & CO_all$visually_valid == 1 & CO_all$duration_valid == 1, 1, ifelse(CO_all$co_cf_conf == "hi" & CO_all$visually_valid ==2 & (CO_all$duration_valid == 1 | CO_all$duration_valid == 2), 2, ifelse(CO_all$co_cf_conf == "hi" & CO_all$visually_valid == 1 & CO_all$duration_valid == 2, 2, ifelse(CO_all$co_cf_conf == "lo" & (CO_all$visually_valid == 1 | CO_all$visually_valid == 2) & (CO_all$duration_valid == 1 | CO_all$duration_valid == 2), 3, ifelse(CO_all$visually_valid == 3 | CO_all$duration_valid == 3 | CO_all$co_cf_conf == "none", 4, NA)))))
# 
# # Check forms
# colSums(is.na(CO_all)) # check for unexpected NAs
# unique(CO_all[!is.na(CO_all$visually_valid) & is.na(CO_all$validated.by), "lascar"])
# 
# ### Remove files that haven't been validated yet 
# CO_all <- CO_all[!is.na(CO_all$visually_valid),]
# nrow(CO_all) #6619
# 
# 
# # merge with previously validated
# former <- readRDS("/Users/ashlinn/Dropbox/Ghana_exposure_data_SHARED (1)/CO_files_processed/CO_parameters_validated_11378sessions_May09.rds")
# former <- subset(former, select = -ids)
# former <- subset(former, select = -ids)
# CO_all <- subset(CO_all, select = -c(year, month, day))
# CO_all$set <- "params2"
# CO_all$is_duplicated <- NA
# 
# # align variables
# former <- former[, c(1:26, 31:33, 27:30)]
# 
# CO_merged <- rbind(former, CO_all)
# table(CO_merged$visually_valid, useNA = "always")
# table(CO_merged$overall_valid, useNA = "always")
# 
# ### save
# saveRDS(CO_merged, file = paste0("CO_parameters_validated_", nrow(CO_merged), "sessions_", format(Sys.Date(), format = "%b%d"), ".rds"))
# 
# 
# 
# ## Combine to remove duplicates --------------
# # params1 <- readRDS("/Users/ashlinn/Dropbox/Ghana_exposure_data_SHARED (1)/CO_files_processed/CO_parameters_validated_6619sessions_Jan30.rds")
# # params2 <- readRDS("/Users/ashlinn/Dropbox/Ghana_exposure_data_SHARED (1)/CO_files_processed/CO_parameters_5041sessions_2016Jan30.rds")
# 
# # params1$set <- "params1"
# # params2$set <- "params2"
# # params <- rbind.fill(params1, params2) #11660 rows
# # params$cstudyid <- blank2na(params$cstudyid)
# # params$ids <- paste(as.character(params[,6]), as.character(params[,7]), as.character(params[,8]))
# 
# 
# sum(duplicated(CO_merged$newid)) #25
# sum(duplicated(CO_merged[,c(1,3:10, 27,30:31)])) # 21
# CO_merged <- CO_merged[!duplicated(CO_merged[,c(1,3:10, 27,30:31)]),]
# CO_merged$rownumber <- row.names(CO_merged)
# dups <- CO_merged$newid[duplicated(CO_merged$newid)] 
# 
# duprows <- CO_merged[CO_merged$newid %in% dups,] #8
# duprows <- arrange(duprows, newid)
# 
# duprows <- duprows[,c(1,3:10, 27,30:31)]
# duprows <- duprows[!duplicated(duprows),] # 29, still 4 problems: 2 with child ID, 2 with validation
# 
# CO_merged <- CO_merged[!CO_merged$rownumber %in% c(10014, 11553),] # the 2 with discordant validation - checked
# 
# params <- CO_merged
# 
# # save parameters file WITH validation: "CO_parameters_all_..." THE FINAL FILE ------
# saveRDS(params, file = paste0(paste0("CO_parameters_all_", nrow(params), "sessions_", format(Sys.Date(), format = "%b%d"), ".rds")))
# 
# # unvalidated <- params[is.na(params$visually_valid),]
# # saveRDS(unvalidated, file = paste0(paste0("CO_parameters_unvalidated_", nrow(unvalidated), "sessions_", format(Sys.Date(), format = "%b%d"), ".rds")))
# 
# # go back to the top to process unvalidated files so they'll line up with the plots


### COMBINE WITH MASTER VALIDATION INFO ####
CO_parameters <- readRDS("/Users/Adoption/Dropbox/Ghana_exposure_data_SHARED_2014/CO_files_processed/CO_parameters_11898sessions_2016Jun10.rds")
validation <- readRDS("/Users/Adoption/Dropbox/Ghana_exposure_data_SHARED_2014/CO_files_processed/CO_validation_info_11892sessions_2016Jun05.rds")

#make a unique id to match both data frames
CO_parameters$newid <- paste(CO_parameters$lascar, CO_parameters$sn, CO_parameters$mstudyid, year(CO_parameters$firstdate), month(CO_parameters$firstdate), day(CO_parameters$firstdate), sep = "_")

CO_withvalidation <- merge(CO_parameters, validation[, 1:7], by = "newid", all.x = TRUE)
CO_withvalidation <- rename(CO_withvalidation, file_from_parameters = file)
CO_withvalidation <- rename(CO_withvalidation, file_from_validation = file_all)

# fix a few session typos
CO_withvalidation$session[CO_withvalidation$session == "s01"] <- "s_01"
CO_withvalidation$session[CO_withvalidation$session == "s2"] <- "s_02"
CO_withvalidation$session[CO_withvalidation$session == "s_2"] <- "s_02"
CO_withvalidation$session[CO_withvalidation$session == "s_0"] <- "s_02"
CO_withvalidation$session[CO_withvalidation$session == "s_15"] <- "s_01"
CO_withvalidation$session[basename(CO_withvalidation$file_from_parameters) == "CU_CO_104_BM1546M_22Jun15_s_05_dup.txt"] <- "s_04"

# blank to NA
blank2na <- function(x){ 
  z <- gsub("\\s+", "", x)  #make sure it's "" and not " " etc
  x[z==""] <- NA 
  return(x)
}

CO_withvalidation$cstudyid <- blank2na(CO_withvalidation$cstudyid)
# check sessions
# mother files
sessioncheck <- data.frame(table(CO_withvalidation$mstudyid[is.na(CO_withvalidation$cstudyid)], CO_withvalidation$session[is.na(CO_withvalidation$cstudyid)]))
max(sessioncheck$Freq) # 2

# child files
sessioncheck2 <- data.frame(table(CO_withvalidation$cstudyid[!is.na(CO_withvalidation$cstudyid)], CO_withvalidation$session[!is.na(CO_withvalidation$cstudyid)]))
max(sessioncheck2$Freq) # 2

colSums(table(CO_withvalidation$cstudyid[!is.na(CO_withvalidation$cstudyid)], CO_withvalidation$session[!is.na(CO_withvalidation$cstudyid)])) # 11 child sessions are s_05, 8 are s_06, and 5 are s_07.

CO_withvalidation$session[!is.na(CO_withvalidation$cstudyid) & CO_withvalidation$session == "s_05"] <- "s_01"
CO_withvalidation$session[!is.na(CO_withvalidation$cstudyid) & CO_withvalidation$session == "s_06"] <- "s_02"


# add "newsession" with M or C prefix for mother or child
CO_withvalidation$newsession <- ifelse(!is.na(CO_withvalidation$cstudyid), paste("C", substr(CO_withvalidation$session, 3, 4), sep = "_"), paste("M", substr(CO_withvalidation$session, 3,4), sep = "_"))


### SAVE DATA WITH VALIDATION ####

saveRDS(CO_withvalidation, file =  paste0("FINAL_CO_parameters_withvalidation_", format(Sys.Date(), format = "%Y%b%d"), ".rds" ))
write.csv(CO_withvalidation, file =  paste0("FINAL_CO_parameters_withvalidation_", format(Sys.Date(), format = "%Y%b%d"), ".csv" ), row.names = FALSE)

###############Other stuff for review purposes, not necessary ######


# generate 10% of previously validated data for Myla to review-----
params <- readRDS("/Users/ashlinn/Dropbox/Ghana_exposure_data_SHARED (1)/CO_files_processed/CO_parameters_validated_11378sessions_May09.rds")
prior <- params[params$set == "params1" & params$visually_valid >1,]
tenpercent <- sample(1:1037, 500, replace=FALSE)
reeval <- prior[tenpercent,]
names(reeval)
reeval[, c("visually_valid", "visual_notes", "validated.by")] <- NA
reeval <- reeval[, c("file", "lascar", "sn", "firstdate", "mstudyid", "session", "co_cf", "co_cf_conf", "co_hours", "visually_valid", "visual_notes", "validated.by")]
reeval <- arrange(reeval, lascar, sn, firstdate)

write.csv(reeval, file = "CO_to_reevaluate2.csv", row.names = FALSE)


## 
new <- read.csv("/Users/ashlinn/Dropbox/Plots by SN_Dec2014/CO_to_reevaluate2.csv", stringsAsFactors = FALSE)
head(new)
new$firstdate <- mdy_hm(new$firstdate)
new$newid <-  paste(new$lascar, new$sn, new$mstudyid, year(new$firstdate), month(new$firstdate), day(new$firstdate), sep = "_")

redone <- params[params$newid %in% new$newid,]
redone <- merge(redone, new[, c("newid", "co_hours", "visually_valid", "visual_notes")], by = "newid")
redone <- redone[!is.na(redone$visually_valid.y),]
redone$diff <- redone$visually_valid.x - redone$visually_valid.y
redone <- redone[, c(1:7, 40:49)]
table(redone$visually_valid.x, redone$visually_valid.y)

write.csv(redone, file = "redone.csv", row.names = FALSE)

discrepant <- redone[redone$visually_valid.x !=redone$visually_valid.y,]
write.csv(discrepant, file = "discrepant.csv", row.names = FALSE)

sum(regexpr("duration|Duration", discrepant$visual_notes.x) != -1, na.rm = TRUE) # 32 were coded due to duration in 1st go-round

sum(regexpr("malfunction|Invalidate|invalidate", discrepant$visual_notes.x) != -1, na.rm = TRUE)  #22

